# .env file
OPENAI_API_KEY=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
AZURE_OPENAI_API_KEY=ea9f2b1af53843eca4b422cec879e518
HUGGING_FACE_API_KEY=**************************
ANOTHER_API_KEY=1234567890234567890

https://pws-gpt4.openai.azure.com/
Eastus2
a8aa2e071eef46ef921de6add911e091
813f4ed1b8514e888368b157a2ba9b09

https://quoc-ngo-openai.openai.azure.com/
Eastus
ea9f2b1af53843eca4b422cec879e518
24b6c5c37eb743989333ec0df142fa6f


# Load local env - old way
#from dotenv import load_dotenv, find_dotenv
#_=load_dotenv(find_dotenv()) # read local .env file
#client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])

@linhht ➜ /workspaces/test (master) $ pip install --upgrade flask python-dotenv-vault
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ npx dotenv-vault@latest new vlt_7ff30dc191616f40a6b2655a35973f4a99b98a2c9deee508053506fb94da583d
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ npm install -g npm@10.2.5
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ npx dotenv-vault@latest pull
local:    Login URL: https://vault.dotenv.org/login?DOTENV_VAULT=vlt_7ff30dc191616f40a6b2655a35973f4a99b98a2c9deee508053506fb94da583d&requestUid=req_857da7fee6a3eb61f596174814d6373520dc2e8c971fe4d2608c7a49e6f1877d
local:    Press y (or any key) to open up the browser to login and generate credential (.env.me) or q to exit: y
local:    Opening browser to https://vault.dotenv.org/login?DOTENV_VAULT=vlt_7ff30dc191616f40a6b2655a35973f4a99b98a2c9deee508053506fb94da583d&requestUid=req_857da7fee6a3eb61f596174814d6373520dc2e8c971fe4d2608c7a49e6f1877d
local:    Waiting for login and credential (.env.me) to be generated... done
local:    Created .env.me (DOTENV_ME=me_ad15c3...)
remote:   Securely pulling... done
remote:   Securely pulled development (.env)
remote:   Securely built vault (.env.vault)
@linhht ➜ /workspaces/test (master) $ npx dotenv-vault@latest open production
local:    Project URL: https://vault.dotenv.org/open?DOTENV_VAULT=vlt_7ff30dc191616f40a6b2655a35973f4a99b98a2c9deee508053506fb94da583d&environment=production
local:    Press y (or any key) to open up the browser to view your project or q to exit: y
local:    Opening project page... done
local:    Opening browser to https://vault.dotenv.org/open?DOTENV_VAULT=vlt_7ff30dc191616f40a6b2655a35973f4a99b98a2c9deee508053506fb94da583d&environment=production

Next run npx dotenv-vault@latest push to push your .env file
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ npx dotenv-vault@latest build
remote:   Securely building .env.vault... done
remote:   Securely built .env.vault

Next:
1. Commit .env.vault to code
2. Set DOTENV_KEY on server
3. Deploy your code

(run npx dotenv-vault@latest keys to view DOTENV_KEYs)
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ git add .env.vault
 .env.vault file for deploy"
@linhht ➜ /workspaces/test (master) $ git commit -am "Build encrypted .env.vault file for deploy"
[master b9a89b8] Build encrypted .env.vault file for deploy
 3 files changed, 70 insertions(+), 8 deletions(-)
 create mode 100644 .env.vault
@linhht ➜ /workspaces/test (master) $ 
@linhht ➜ /workspaces/test (master) $ npx dotenv-vault@latest keys production
remote:   Listing .env.vault decryption keys... done
dotenv://:key_3e01f516ab3afccab63494b905a641d5cb978d3640d6d3d6a4e29f3e76fb58ec@dotenv.org/vault/.env.vault?environment=production
@linhht ➜ /workspaces/test (master) $ 

This will output your production DOTENV_KEY. Use that DOTENV_KEY to run your application in production mode.

$ DOTENV_KEY='dotenv://:key_1234@dotenv.org/vault/.env.vault?environment=production' flask --app index run
# visit http://127.0.0.1:5000

DOTENV_KEY='dotenv://:key_3e01f516ab3afccab63494b905a641d5cb978d3640d6d3d6a4e29f3e76fb58ec@dotenv.org/vault/.env.vault?environment=production' python myLangchainChatbot.py

py myLangchainChatbot.py
alias py="DOTENV_KEY='dotenv://:key_3e01f516ab3afccab63494b905a641d5cb978d3640d6d3d6a4e29f3e76fb58ec@dotenv.org/vault/.env.vault?environment=production' python"

DOTENV_KEY='dotenv://:key_3e01f516ab3afccab63494b905a641d5cb978d3640d6d3d6a4e29f3e76fb58ec@dotenv.org/vault/.env.vault?environment=production' panel serve myLangchainChatbot.py --show

@linhht ➜ /workspaces/test (master) $ panel serve myLangchainChatbot.py --show
2023-12-08 08:59:37,324 Starting Bokeh server version 3.3.2 (running on Tornado 6.3.3)
2023-12-08 08:59:37,325 User authentication hooks NOT provided (default user enabled)
2023-12-08 08:59:37,338 Bokeh app running at: http://localhost:5006/myLangchainChatbot
2023-12-08 08:59:37,338 Starting Bokeh server with process id: 57488
2023-12-08 08:59:42,377 Error running application handler <bokeh.application.handlers.script.ScriptHandler object at 0x7fcb491b4f10>: [Errno 2] No such file or directory: ''
File 'main.py', line 68, in load_dotenv:
stream = open(dotenv_path) if not stream else stream Traceback (most recent call last):
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/bokeh/application/handlers/code_runner.py", line 229, in run
    exec(self._code, module.__dict__)
  File "/workspaces/test/myLangchainChatbot.py", line 33, in <module>
    load_dotenv()
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/dotenv_vault/main.py", line 68, in load_dotenv
    stream = open(dotenv_path) if not stream else stream
FileNotFoundError: [Errno 2] No such file or directory: ''
 
2023-12-08 08:59:43,275 WebSocket connection opened
2023-12-08 08:59:43,275 ServerConnection created
2023-12-08 09:00:04,514 WebSocket connection closed: code=1001, reason=None
2023-12-08 09:00:11,759 Error running application handler <bokeh.application.handlers.script.ScriptHandler object at 0x7fcb491b4f10>: [Errno 2] No such file or directory: ''
File 'main.py', line 68, in load_dotenv:
stream = open(dotenv_path) if not stream else stream Traceback (most recent call last):
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/bokeh/application/handlers/code_runner.py", line 229, in run
    exec(self._code, module.__dict__)
  File "/workspaces/test/myLangchainChatbot.py", line 33, in <module>
    load_dotenv()
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/dotenv_vault/main.py", line 68, in load_dotenv
    stream = open(dotenv_path) if not stream else stream
FileNotFoundError: [Errno 2] No such file or directory: ''
 
2023-12-08 09:00:12,104 WebSocket connection opened
2023-12-08 09:00:12,105 ServerConnection created
2023-12-08 09:00:16,417 WebSocket connection closed: code=1001, reason=None
^C
Interrupted, shutting down

############### my 1st langchain chatbot ###############
This Python script is for a chatbot that uses the OpenAI API and the Langchain library to answer questions based on a set of documents. \
Here's a high-level overview of what the script does:

1. It imports necessary libraries and sets up the OpenAI client with your API key.

2. It sets up a language model (llm) using the OpenAI API.

3. It sets up a vector database using the Langchain library, which is used to find documents that are similar to a given question.

4. It initializes a chat model and a prompt template for the chatbot.

5. It sets up a retrieval question-answering (QA) chain, which uses the vector database to find relevant documents and \
the language model to generate answers.

6. It sets up a memory buffer to keep track of the chat history.

7. It sets up a conversational retrieval chain, which uses the retrieval QA chain and the memory buffer to answer questions \
in a conversational manner.

8. It defines a function to load a database from a PDF file and create a chatbot chain.

9. It defines a class for the chatbot, which includes methods for loading the database, running the conversational chain, \
and displaying the chat history and database queries.

10. It sets up a user interface for the chatbot using the Panel library.

11. Finally, it makes the chatbot available as a web service.

Please note that the code is quite complex and involves several advanced topics, including natural language processing, \
vector databases, and web services. If you have specific questions about certain parts of the code, feel free to ask!
########################################################

############### sqlite3 chroma error ###############
RuntimeError: Your system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.
Please visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.

# To support sqlite3
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

Got another error:
create chroma db from_documents 
AttributeError: type object 'hnswlib.Index' has no attribute 'file_handle_count'

Solve: install chromadb 0.4.3
pip uninstall chromadb
pip install chromadb==0.4.3

############## Tell ChatGPT which tool it can use - test with  https://platform.openai.com/playground ##############
You have access to the following tools:

- run_query: run a sqlite query and return the result. Accept an argument of a sql query as a string.

To use the tool, always respond with the following format:

{
  "name":<name of a tool to use>,
  "argument":<argument to pass to the tool>
}

How many open orders do we have?